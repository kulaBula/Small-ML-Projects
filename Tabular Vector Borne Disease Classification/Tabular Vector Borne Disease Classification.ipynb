{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13785b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the tools you will need\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7226a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sudden_fever</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headache</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouth_bleed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nose_bleed</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ulcers</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toenail_loss</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech_problem</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bullseye_rash</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prognosis</th>\n",
       "      <td>Lyme_disease</td>\n",
       "      <td>Tungiasis</td>\n",
       "      <td>Lyme_disease</td>\n",
       "      <td>Zika</td>\n",
       "      <td>Rift_Valley_fever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0          1             2     3                  4\n",
       "id                         0          1             2     3                  4\n",
       "sudden_fever             1.0        0.0           0.0   0.0                0.0\n",
       "headache                 1.0        0.0           1.0   0.0                0.0\n",
       "mouth_bleed              0.0        0.0           1.0   1.0                0.0\n",
       "nose_bleed               1.0        0.0           1.0   1.0                0.0\n",
       "...                      ...        ...           ...   ...                ...\n",
       "ulcers                   0.0        0.0           0.0   0.0                1.0\n",
       "toenail_loss             0.0        0.0           1.0   0.0                1.0\n",
       "speech_problem           0.0        0.0           1.0   0.0                0.0\n",
       "bullseye_rash            0.0        0.0           1.0   0.0                0.0\n",
       "prognosis       Lyme_disease  Tungiasis  Lyme_disease  Zika  Rift_Valley_fever\n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148642a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "sudden_fever      0\n",
       "headache          0\n",
       "mouth_bleed       0\n",
       "nose_bleed        0\n",
       "                 ..\n",
       "ulcers            0\n",
       "toenail_loss      0\n",
       "speech_problem    0\n",
       "bullseye_rash     0\n",
       "prognosis         0\n",
       "Length: 66, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The prognosis column can be turned into a categories \n",
    "# check if there are any missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5489e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  int64\n",
       "sudden_fever      float64\n",
       "headache          float64\n",
       "mouth_bleed       float64\n",
       "nose_bleed        float64\n",
       "                   ...   \n",
       "ulcers            float64\n",
       "toenail_loss      float64\n",
       "speech_problem    float64\n",
       "bullseye_rash     float64\n",
       "prognosis          object\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c45b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prognosis\n"
     ]
    }
   ],
   "source": [
    "for label, content in df.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b7b58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 707 entries, 0 to 706\n",
      "Data columns (total 66 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   id                     707 non-null    int64   \n",
      " 1   sudden_fever           707 non-null    float64 \n",
      " 2   headache               707 non-null    float64 \n",
      " 3   mouth_bleed            707 non-null    float64 \n",
      " 4   nose_bleed             707 non-null    float64 \n",
      " 5   muscle_pain            707 non-null    float64 \n",
      " 6   joint_pain             707 non-null    float64 \n",
      " 7   vomiting               707 non-null    float64 \n",
      " 8   rash                   707 non-null    float64 \n",
      " 9   diarrhea               707 non-null    float64 \n",
      " 10  hypotension            707 non-null    float64 \n",
      " 11  pleural_effusion       707 non-null    float64 \n",
      " 12  ascites                707 non-null    float64 \n",
      " 13  gastro_bleeding        707 non-null    float64 \n",
      " 14  swelling               707 non-null    float64 \n",
      " 15  nausea                 707 non-null    float64 \n",
      " 16  chills                 707 non-null    float64 \n",
      " 17  myalgia                707 non-null    float64 \n",
      " 18  digestion_trouble      707 non-null    float64 \n",
      " 19  fatigue                707 non-null    float64 \n",
      " 20  skin_lesions           707 non-null    float64 \n",
      " 21  stomach_pain           707 non-null    float64 \n",
      " 22  orbital_pain           707 non-null    float64 \n",
      " 23  neck_pain              707 non-null    float64 \n",
      " 24  weakness               707 non-null    float64 \n",
      " 25  back_pain              707 non-null    float64 \n",
      " 26  weight_loss            707 non-null    float64 \n",
      " 27  gum_bleed              707 non-null    float64 \n",
      " 28  jaundice               707 non-null    float64 \n",
      " 29  coma                   707 non-null    float64 \n",
      " 30  diziness               707 non-null    float64 \n",
      " 31  inflammation           707 non-null    float64 \n",
      " 32  red_eyes               707 non-null    float64 \n",
      " 33  loss_of_appetite       707 non-null    float64 \n",
      " 34  urination_loss         707 non-null    float64 \n",
      " 35  slow_heart_rate        707 non-null    float64 \n",
      " 36  abdominal_pain         707 non-null    float64 \n",
      " 37  light_sensitivity      707 non-null    float64 \n",
      " 38  yellow_skin            707 non-null    float64 \n",
      " 39  yellow_eyes            707 non-null    float64 \n",
      " 40  facial_distortion      707 non-null    float64 \n",
      " 41  microcephaly           707 non-null    float64 \n",
      " 42  rigor                  707 non-null    float64 \n",
      " 43  bitter_tongue          707 non-null    float64 \n",
      " 44  convulsion             707 non-null    float64 \n",
      " 45  anemia                 707 non-null    float64 \n",
      " 46  cocacola_urine         707 non-null    float64 \n",
      " 47  hypoglycemia           707 non-null    float64 \n",
      " 48  prostraction           707 non-null    float64 \n",
      " 49  hyperpyrexia           707 non-null    float64 \n",
      " 50  stiff_neck             707 non-null    float64 \n",
      " 51  irritability           707 non-null    float64 \n",
      " 52  confusion              707 non-null    float64 \n",
      " 53  tremor                 707 non-null    float64 \n",
      " 54  paralysis              707 non-null    float64 \n",
      " 55  lymph_swells           707 non-null    float64 \n",
      " 56  breathing_restriction  707 non-null    float64 \n",
      " 57  toe_inflammation       707 non-null    float64 \n",
      " 58  finger_inflammation    707 non-null    float64 \n",
      " 59  lips_irritation        707 non-null    float64 \n",
      " 60  itchiness              707 non-null    float64 \n",
      " 61  ulcers                 707 non-null    float64 \n",
      " 62  toenail_loss           707 non-null    float64 \n",
      " 63  speech_problem         707 non-null    float64 \n",
      " 64  bullseye_rash          707 non-null    float64 \n",
      " 65  prognosis              707 non-null    category\n",
      "dtypes: category(1), float64(64), int64(1)\n",
      "memory usage: 360.2 KB\n"
     ]
    }
   ],
   "source": [
    "# Turn the prognosis column into categories\n",
    "for label, content in df.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df[label] = content.astype(\"category\").cat.as_ordered()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be2eb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Chikungunya', 'Dengue', 'Japanese_encephalitis', 'Lyme_disease',\n",
       "       'Malaria', 'Plague', 'Rift_Valley_fever', 'Tungiasis',\n",
       "       'West_Nile_fever', 'Yellow_Fever', 'Zika'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prognosis.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88a9ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and Y\n",
    "X = df.drop(\"prognosis\", axis=1)\n",
    "y = df.prognosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6370444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "642209a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d5f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a models dictionary\n",
    "models = {\"LinearSVC\": LinearSVC(),\n",
    "          \"LogisticRegression\": LogisticRegression(),\n",
    "          \"KNN\": KNeighborsClassifier(),\n",
    "          \"RandomForestCls\": RandomForestClassifier(),\n",
    "          \"AdaBoostClf\": AdaBoostClassifier()}\n",
    "baseline_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbe262",
   "metadata": {},
   "source": [
    "Use this article to fix the bug below: \n",
    "\n",
    "https://towardsdatascience.com/mean-average-precision-at-k-map-k-clearly-explained-538d8e032d2\n",
    "\n",
    "I used code from this tutorial here: \n",
    "\n",
    "https://www.kaggle.com/code/nandeshwar/mean-average-precision-map-k-metric-explained-code/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dea9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        # first condition checks whether it is valid prediction\n",
    "        # second condition checks if prediction is not repeated\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f28ab458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jakub\\Small-ML-Projects\\env\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jakub\\Small-ML-Projects\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train); \n",
    "    # Score the model\n",
    "    predictions = model.predict(X_test)\n",
    "    baseline_results[name] = mapk(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "307e228c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearSVC': 0.20338705513504304,\n",
       " 'LogisticRegression': 0.3515945008676397,\n",
       " 'KNN': 0.22445076543919604,\n",
       " 'RandomForestCls': 0.3368960189709687,\n",
       " 'AdaBoostClf': 0.2503851548444104}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f892b3",
   "metadata": {},
   "source": [
    "Now, since we have established some baseline results we can focus on improving them. We will start with improving RandomForestClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30739856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1900 candidates, totalling 9500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32m~\\Small-ML-Projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\Small-ML-Projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Small-ML-Projects\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32m~\\Small-ML-Projects\\env\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\Small-ML-Projects\\env\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\Small-ML-Projects\\env\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\Small-ML-Projects\\env\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\Small-ML-Projects\\env\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a GridSearchCV for RandomForestClassifier\n",
    "random_forest_clf_grid = {\"n_estimators\": np.arange(100, 2000, 100),\n",
    "                          \"max_depth\": (5, 8, 15, 25, 30),\n",
    "                          \"min_samples_split\": (2, 5, 10, 15, 100),\n",
    "                          \"min_samples_leaf\": (1, 2, 5, 10)}\n",
    "gs_random_forest_clf = GridSearchCV(RandomForestClassifier(n_jobs=-1, random_state=42),\n",
    "                                    param_grid=random_forest_clf_grid,\n",
    "                                    cv=5,\n",
    "                                    verbose=True,\n",
    "                                    n_jobs=-1)\n",
    "gs_random_forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85d4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained GridSearch RandomForest model\n",
    "import pickle \n",
    "pickle.dump(gs_random_forest_clf, open(\"gs_random_forest_clf\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "gs_random_forest_predictions = gs_random_forest_clf.predict(X_test)\n",
    "updated_results[\"RandomForestCls\"] = mapk(y_test, gs_random_forest_predictions)\n",
    "updated_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dca13d",
   "metadata": {},
   "source": [
    "https://medium.com/codex/do-i-need-to-tune-logistic-regression-hyperparameters-1cb2b81fca69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ce03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Setup GridSearchCV for LogisticRegression\n",
    "logistic_regression_grid = {\"C\": (0.1, 1, 10, 100, 1000),\n",
    "                            \"max_iter\": np.arange(100,1000,10),\n",
    "                            \"solver\": (\"liblinear\", \"sag\", \"lbfgs\")}\n",
    "\n",
    "gs_logistic_regression = GridSearchCV(LogisticRegression(),\n",
    "                                      param_grid=logistic_regression_grid,\n",
    "                                      cv=5, \n",
    "                                      verbose=True,\n",
    "                                      n_jobs=-1)\n",
    "gs_logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "pickle.dump(gs_logistic_regression, open(\"gs_logistic_regression\", \"wb\"))\n",
    "# Make predictions\n",
    "gs_logistic_regression_predictions = gs_logistic_regression.predict(X_test)\n",
    "updated_results[\"LogisticRegression\"] = mapk(y_test, gs_logistic_regression_predictions)\n",
    "updated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c579b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Setup GridSearchCV for AdaBoostClf\n",
    "ada_boost_grid = {\"n_estimators\": (10, 50, 100, 500, 1000, 5000),\n",
    "                  \"learning_rate\": np.arange(0.1, 2.1, 0.1)}\n",
    "gs_ada_boost = GridSearchCV(AdaBoostClassifier(), \n",
    "                            param_grid=ada_boost_grid, \n",
    "                            cv=5, \n",
    "                            verbose=True,\n",
    "                            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4080ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "pickle.dump(gs_ada_boost, open(\"gs_ada_boost\", \"wb\"))\n",
    "# Make predictions\n",
    "gs_ada_boost_predictions = gs_ada_boost.predict(X_test)\n",
    "updated_results[\"AdaBoostClf\"] = mapk(y_test, gs_ada_boost_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
